{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing for xBD Dataset ###\n",
    "This notebook handles all the required cropping and data processing for the xBD dataset. It takes in raw satellite images and outputs crops of buildings labeled as either damaged or undamaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'guatemala-volcano', 'midwest-flooding', 'hurricane-harvey', 'santa-rosa-wildfire', 'hurricane-michael', 'hurricane-florence', 'hurricane-matthew', 'palu-tsunami', 'socal-fire'}\n"
     ]
    }
   ],
   "source": [
    "# find all disasters and list names in xBD tier 1 dataset\n",
    "filepath = 'xBD_Dataset/geotiffs/tier1/images'\n",
    "contents = os.listdir(filepath)\n",
    "disaster_names = set()\n",
    "for i in contents:\n",
    "    disaster_names.add(re.findall(r\"([\\w,-]+)_\\d\", i)[0])\n",
    "print(disaster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moore-tornado', 'pinery-bushfire', 'joplin-tornado', 'tuscaloosa-tornado', 'lower-puna-volcano', 'woolsey-fire', 'sunda-tsunami', 'portugal-wildfire', 'nepal-flooding'}\n"
     ]
    }
   ],
   "source": [
    "# find all disasters and list names in xBD tier 3 dataset\n",
    "filepath = 'xBD_Dataset/geotiffs/tier3/images'\n",
    "contents = os.listdir(filepath)\n",
    "disaster_names = set()\n",
    "for i in contents:\n",
    "    disaster_names.add(re.findall(r\"([\\w,-]+)_\\d\", i)[0])\n",
    "print(disaster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to better match our use case, apply transfer learning only on the following datasets:\n",
    "usable_disasters = ['santa-rosa-wildfire', 'socal-fire', 'joplin-tornado','woolsey-fire','tuscaloosa-tornado', 'moore-tornado', 'portugal-wildfire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original directory already contains training, hold, and test folders\n",
    "# however, we want to create our own train/validation/test splits\n",
    "# therefore, we grab all images from the three folders (tier1, hold, test) and extract buildings\n",
    "\n",
    "# create counter mechanism for names of cropped images\n",
    "counter = dict()\n",
    "for name in usable_disasters:\n",
    "    counter.update({name:0})\n",
    "\n",
    "for folder in ['xBD_Dataset/geotiffs/tier1','xBD_Dataset/geotiffs/tier3','xBD_Dataset/geotiffs/hold','xBD_Dataset/geotiffs/test']:\n",
    "    contents = os.listdir(folder + '/labels')\n",
    "    for label_path in contents:\n",
    "        current_disaster = re.findall(r\"([\\w,-]+)_\\d\", label_path)[0]\n",
    "        if (current_disaster in usable_disasters) and ('post' in label_path):\n",
    "            image_path = label_path[:-5] + '.tif'\n",
    "            \n",
    "            label = pd.read_json(folder + '/labels/' + label_path)['features']['xy']\n",
    "            df = pd.json_normalize(label)\n",
    "            for j in range(df.shape[0]):\n",
    "                coords = df.loc[j,'wkt']\n",
    "                uid = df.loc[j,'properties.uid']\n",
    "                damage_type = df.loc[j,'properties.subtype']\n",
    "                \n",
    "                # use regex to extract two groups corresponding to the pixel x and y values of the building\n",
    "                result = re.findall(r\"(\\d+\\.\\d+)\\s(\\d+\\.\\d+)\", coords)\n",
    "\n",
    "                xvals = []\n",
    "                yvals = []\n",
    "                for i in result:\n",
    "                    xvals.append(float(i[0]))\n",
    "                    yvals.append(float(i[1]))\n",
    "\n",
    "                ymax = max(yvals) + 10\n",
    "                ymin = min(yvals) - 10\n",
    "                xmax = max(xvals) + 10\n",
    "                xmin = min(xvals) - 10\n",
    "                \n",
    "                # discard this building if too small for human to make reliable prediction\n",
    "                if ((ymax - ymin) < 40 or (xmax - xmin) < 40):\n",
    "                    continue\n",
    "\n",
    "                with rasterio.open(folder + '/images/' + image_path) as src:\n",
    "                    # aff = src.transform\n",
    "                    # Make sure not extracting pixels that are out of bounds\n",
    "                    rxmin, rymin, rxmax, rymax = (0, 0, src.shape[1], src.shape[0])\n",
    "                    ymax = min(ymax,rymax)\n",
    "                    ymin = max(ymin,rymin)\n",
    "                    xmax = min(xmax,rxmax)\n",
    "                    xmin = max(xmin,rxmin)\n",
    "\n",
    "                    window = ((int(ymin), int(ymax)), (int(xmin), int(xmax)))\n",
    "                    # Read croped array\n",
    "                    arr1 = src.read(1, window=window)\n",
    "                    arr2 = src.read(2, window=window)\n",
    "                    arr3 = src.read(3, window=window)\n",
    "\n",
    "                # output image of cropped building\n",
    "                rgb = np.dstack((arr1,arr2,arr3)).astype(np.uint8)\n",
    "                new_image = Image.fromarray(rgb)\n",
    "                \n",
    "                if damage_type in ['no-damage','minor-damage']:\n",
    "                    damage_status = 'undamaged'\n",
    "                else:\n",
    "                    damage_status = 'damaged'\n",
    "                \n",
    "                counter[current_disaster] += 1\n",
    "                save_path = './xBD_Dataset/' + damage_status + '/'\n",
    "                save_name = current_disaster + '-' + str(counter[current_disaster]) + '-' + damage_status + '.png'\n",
    "                new_image.save(save_path + save_name)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 17676 buildings for disaster santa-rosa-wildfire\n",
      "Processed 13491 buildings for disaster socal-fire\n",
      "Processed 9640 buildings for disaster joplin-tornado\n",
      "Processed 3756 buildings for disaster woolsey-fire\n",
      "Processed 10681 buildings for disaster tuscaloosa-tornado\n",
      "Processed 16881 buildings for disaster moore-tornado\n",
      "Processed 14657 buildings for disaster portugal-wildfire\n",
      "Processed 86782 buildings in total\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for key, val in counter.items():\n",
    "    print('Processed ' + str(val) + ' buildings for disaster ' + key)\n",
    "    total += val\n",
    "print('Processed ' + str(total) + ' buildings in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "widths = []\n",
    "heights = []\n",
    "for name in glob.glob('./xBD_Dataset/building_crops/*/*'):\n",
    "    with Image.open(name) as img:\n",
    "        widths.append(img.size[0])\n",
    "        heights.append(img.size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.0\n",
      "58.0\n"
     ]
    }
   ],
   "source": [
    "print(np.median(widths))\n",
    "print(np.median(heights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.68584499089673\n",
      "61.75250628010417\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(widths))\n",
    "print(np.mean(heights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86782"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widths.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to better match our use case, apply transfer learning only on the following datasets:\n",
    "testing_disasters = ['pinery-bushfire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2353 buildings for disaster pinery-bushfire\n",
      "Processed 2353 buildings in total\n"
     ]
    }
   ],
   "source": [
    "# create counter mechanism for names of cropped images\n",
    "counter = dict()\n",
    "for name in testing_disasters:\n",
    "    counter.update({name:0})\n",
    "\n",
    "for folder in ['xBD_Dataset/geotiffs/tier1','xBD_Dataset/geotiffs/tier3','xBD_Dataset/geotiffs/hold','xBD_Dataset/geotiffs/test']:\n",
    "    contents = os.listdir(folder + '/labels')\n",
    "    for label_path in contents:\n",
    "        current_disaster = re.findall(r\"([\\w,-]+)_\\d\", label_path)[0]\n",
    "        if (current_disaster in testing_disasters) and ('post' in label_path):\n",
    "            image_path = label_path[:-5] + '.tif'\n",
    "            \n",
    "            label = pd.read_json(folder + '/labels/' + label_path)['features']['xy']\n",
    "            df = pd.json_normalize(label)\n",
    "            for j in range(df.shape[0]):\n",
    "                coords = df.loc[j,'wkt']\n",
    "                uid = df.loc[j,'properties.uid']\n",
    "                damage_type = df.loc[j,'properties.subtype']\n",
    "                \n",
    "                # use regex to extract two groups corresponding to the pixel x and y values of the building\n",
    "                result = re.findall(r\"(\\d+\\.\\d+)\\s(\\d+\\.\\d+)\", coords)\n",
    "\n",
    "                xvals = []\n",
    "                yvals = []\n",
    "                for i in result:\n",
    "                    xvals.append(float(i[0]))\n",
    "                    yvals.append(float(i[1]))\n",
    "\n",
    "                ymax = max(yvals) + 10\n",
    "                ymin = min(yvals) - 10\n",
    "                xmax = max(xvals) + 10\n",
    "                xmin = min(xvals) - 10\n",
    "                \n",
    "                # discard this building if too small for human to make reliable prediction\n",
    "                if ((ymax - ymin) < 40 or (xmax - xmin) < 40):\n",
    "                    continue\n",
    "\n",
    "                with rasterio.open(folder + '/images/' + image_path) as src:\n",
    "                    # aff = src.transform\n",
    "                    # Make sure not extracting pixels that are out of bounds\n",
    "                    rxmin, rymin, rxmax, rymax = (0, 0, src.shape[1], src.shape[0])\n",
    "                    ymax = min(ymax,rymax)\n",
    "                    ymin = max(ymin,rymin)\n",
    "                    xmax = min(xmax,rxmax)\n",
    "                    xmin = max(xmin,rxmin)\n",
    "\n",
    "                    window = ((int(ymin), int(ymax)), (int(xmin), int(xmax)))\n",
    "                    # Read croped array\n",
    "                    arr1 = src.read(1, window=window)\n",
    "                    arr2 = src.read(2, window=window)\n",
    "                    arr3 = src.read(3, window=window)\n",
    "\n",
    "                # output image of cropped building\n",
    "                rgb = np.dstack((arr1,arr2,arr3)).astype(np.uint8)\n",
    "                new_image = Image.fromarray(rgb)\n",
    "                \n",
    "                if damage_type in ['no-damage','minor-damage']:\n",
    "                    damage_status = 'undamaged'\n",
    "                else:\n",
    "                    damage_status = 'damaged'\n",
    "                \n",
    "                counter[current_disaster] += 1\n",
    "                save_path = './xBD_Dataset/' + damage_status + '/'\n",
    "                save_name = current_disaster + '-' + str(counter[current_disaster]) + '-' + damage_status + '.png'\n",
    "                new_image.save(save_path + save_name)\n",
    "total = 0\n",
    "for key, val in counter.items():\n",
    "    print('Processed ' + str(val) + ' buildings for disaster ' + key)\n",
    "    total += val\n",
    "print('Processed ' + str(total) + ' buildings in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xbd]",
   "language": "python",
   "name": "conda-env-xbd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
